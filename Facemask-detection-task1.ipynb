{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1bb1cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e920839",
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_LR = 1e-4\n",
    "EPOCHS = 20\n",
    "BS = 32\n",
    "directory=\"Datav3\"\n",
    "categories=[\"with_mask\",\"wo_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18561059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading images...\")\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "for imagePath in categories:\n",
    "    path=os.path.join(directory,imagePath)\n",
    "    for img in os.listdir(path):\n",
    "        img_path=os.path.join(path,img)\n",
    "        image = load_img(img_path, target_size=(128, 128))\n",
    "        image = img_to_array(image)\n",
    "        image = preprocess_input(image)\n",
    "        data.append(image)\n",
    "        labels.append(imagePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f2d242",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf20a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,test_size=0.20, stratify=labels, random_state=42)\n",
    "\n",
    "\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed162857",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "                        input_tensor=Input(shape=(128, 128, 3)))\n",
    "baseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c646e963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "                        input_tensor=Input(shape=(48, 48, 3)))\n",
    "\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(2, 2))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(48, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fbbdfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajath.DESKTOP-ELKQ6GV\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:367: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ebeeeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training head...\n",
      "Epoch 1/20\n",
      "1680/1680 [==============================] - ETA: 0s - loss: 0.5654 - accuracy: 0.7156WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 420 batches). You may need to use the repeat() function when building your dataset.\n",
      "1680/1680 [==============================] - 142s 83ms/step - loss: 0.5654 - accuracy: 0.7156 - val_loss: 0.5054 - val_accuracy: 0.7515\n",
      "Epoch 2/20\n",
      "1680/1680 [==============================] - 121s 72ms/step - loss: 0.4672 - accuracy: 0.7845\n",
      "Epoch 3/20\n",
      "1680/1680 [==============================] - 115s 69ms/step - loss: 0.4462 - accuracy: 0.7972\n",
      "Epoch 4/20\n",
      "1680/1680 [==============================] - 115s 68ms/step - loss: 0.4349 - accuracy: 0.8010\n",
      "Epoch 5/20\n",
      "1680/1680 [==============================] - 104s 62ms/step - loss: 0.4246 - accuracy: 0.8089\n",
      "Epoch 6/20\n",
      "1680/1680 [==============================] - 104s 62ms/step - loss: 0.4229 - accuracy: 0.8072\n",
      "Epoch 7/20\n",
      "1680/1680 [==============================] - 104s 62ms/step - loss: 0.4200 - accuracy: 0.8097\n",
      "Epoch 8/20\n",
      "1680/1680 [==============================] - 104s 62ms/step - loss: 0.4144 - accuracy: 0.8109\n",
      "Epoch 9/20\n",
      "1680/1680 [==============================] - 104s 62ms/step - loss: 0.4084 - accuracy: 0.8139\n",
      "Epoch 10/20\n",
      "1680/1680 [==============================] - 103s 61ms/step - loss: 0.4101 - accuracy: 0.8142\n",
      "Epoch 11/20\n",
      "1680/1680 [==============================] - 105s 63ms/step - loss: 0.4038 - accuracy: 0.8197\n",
      "Epoch 12/20\n",
      "1680/1680 [==============================] - 105s 62ms/step - loss: 0.4043 - accuracy: 0.8197\n",
      "Epoch 13/20\n",
      "1680/1680 [==============================] - 103s 62ms/step - loss: 0.4048 - accuracy: 0.8156\n",
      "Epoch 14/20\n",
      "1680/1680 [==============================] - 110s 66ms/step - loss: 0.4020 - accuracy: 0.8196\n",
      "Epoch 15/20\n",
      "1680/1680 [==============================] - 118s 70ms/step - loss: 0.4028 - accuracy: 0.8182\n",
      "Epoch 16/20\n",
      "1680/1680 [==============================] - 118s 70ms/step - loss: 0.4026 - accuracy: 0.8190\n",
      "Epoch 17/20\n",
      "1680/1680 [==============================] - 116s 69ms/step - loss: 0.4001 - accuracy: 0.8208\n",
      "Epoch 18/20\n",
      "1680/1680 [==============================] - 115s 69ms/step - loss: 0.3971 - accuracy: 0.8227\n",
      "Epoch 19/20\n",
      "1680/1680 [==============================] - 116s 69ms/step - loss: 0.3958 - accuracy: 0.8212\n",
      "Epoch 20/20\n",
      "1680/1680 [==============================] - 106s 63ms/step - loss: 0.3954 - accuracy: 0.8212\n",
      "[INFO] evaluating network...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training head...\")\n",
    "H = model.fit(aug.flow(trainX, trainY, batch_size=BS),steps_per_epoch=len(trainX) // BS, validation_data=(testX, testY),\n",
    "    validation_steps=len(testX) // BS,\n",
    "    epochs=EPOCHS)\n",
    "\n",
    "# make predictions on the testing set\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predIdxs = model.predict(testX, batch_size=BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "338c4cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   with_mask       0.78      0.82      0.80      6737\n",
      "     wo_mask       0.81      0.77      0.79      6711\n",
      "\n",
      "    accuracy                           0.80     13448\n",
      "   macro avg       0.80      0.80      0.80     13448\n",
      "weighted avg       0.80      0.80      0.80     13448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "print(classification_report(testY.argmax(axis=1), predIdxs,target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2361b7e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

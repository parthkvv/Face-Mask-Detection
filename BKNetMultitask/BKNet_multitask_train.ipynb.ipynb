{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN2Head_train.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"lqTV4LMgvz46","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638857193927,"user_tz":300,"elapsed":41886,"user":{"displayName":"Sanjana Vijay Ganesh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07562438145748516192"}},"outputId":"71a28c2b-e05f-46bd-b5d7-40d9e961cea9"},"source":["!pip install tensorflow-gpu==1.13.1"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow-gpu==1.13.1\n","  Downloading tensorflow_gpu-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (345.0 MB)\n","\u001b[K     |████████████████████████████████| 345.0 MB 4.3 kB/s \n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.1.0)\n","Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.13.1)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (3.17.3)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (0.37.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.1.2)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.15.0)\n","Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (0.12.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.42.0)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.19.5)\n","Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.13.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (0.8.1)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (0.4.0)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.0.8)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.13.1) (3.1.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.3.6)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (4.8.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.6.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.10.0.2)\n","Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow-gpu==1.13.1) (4.0.3)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow-gpu==1.13.1) (1.5.2)\n","Installing collected packages: tensorflow-gpu\n","Successfully installed tensorflow-gpu-1.13.1\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":959},"id":"GugvVhUjRIZr","executionInfo":{"status":"ok","timestamp":1638857132492,"user_tz":300,"elapsed":38318,"user":{"displayName":"Sanjana Vijay Ganesh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07562438145748516192"}},"outputId":"1b9ced79-3eac-4a64-b2a4-e2a07f571dd5"},"source":["!pip install tensorflow==1.13.1"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow==1.13.1\n","  Downloading tensorflow-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (92.6 MB)\n","\u001b[K     |████████████████████████████████| 92.6 MB 1.4 MB/s \n","\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.2)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.15.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (3.17.3)\n","Collecting keras-applications>=1.0.6\n","  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 6.2 MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.12.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.8.1)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.0)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.4.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.42.0)\n","Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n","  Downloading tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367 kB)\n","\u001b[K     |████████████████████████████████| 367 kB 36.7 MB/s \n","\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.37.0)\n","Collecting tensorboard<1.14.0,>=1.13.0\n","  Downloading tensorboard-1.13.1-py3-none-any.whl (3.2 MB)\n","\u001b[K     |████████████████████████████████| 3.2 MB 32.0 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.19.5)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (3.1.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.3.6)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (1.0.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (4.8.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.6.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.10.0.2)\n","Collecting mock>=2.0.0\n","  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.13.1) (1.5.2)\n","Installing collected packages: mock, tensorflow-estimator, tensorboard, keras-applications, tensorflow\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.7.0\n","    Uninstalling tensorflow-estimator-2.7.0:\n","      Successfully uninstalled tensorflow-estimator-2.7.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.7.0\n","    Uninstalling tensorboard-2.7.0:\n","      Successfully uninstalled tensorboard-2.7.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.7.0\n","    Uninstalling tensorflow-2.7.0:\n","      Successfully uninstalled tensorflow-2.7.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","kapre 0.3.6 requires tensorflow>=2.0.0, but you have tensorflow 1.13.1 which is incompatible.\u001b[0m\n","Successfully installed keras-applications-1.0.8 mock-4.0.3 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["tensorboard","tensorflow"]}}},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UkTthIob3the","executionInfo":{"status":"ok","timestamp":1638857264375,"user_tz":300,"elapsed":1967,"user":{"displayName":"Sanjana Vijay Ganesh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07562438145748516192"}},"outputId":"586807fc-e7a8-4c19-84ec-b86ab9be5ef8"},"source":["import os\n","import numpy as np\n","import CNN2Head_input\n","import tensorflow as tf\n","\n","import BKNetStyle\n","from const import *\n","import time\n","import math\n","%load_ext autoreload\n","%autoreload 2\n","from copy import copy, deepcopy"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ao5lG9eQ34kQ","executionInfo":{"status":"ok","timestamp":1638030263608,"user_tz":300,"elapsed":24039,"user":{"displayName":"Sanjana Vijay Ganesh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07562438145748516192"}},"outputId":"0f6c9ec7-688c-45dd-a008-f2761a4fe29c"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"UaW23Cd33thk"},"source":["NUM_CLASSES = 3\n","\n","def normalise(x):\n","    return (x-128)/255.0\n","\n","def load_mini_dataset(index):\n","    \n","    label_to_int = {\"Mask\":0,\"Mask_Mouth_Chin\":1,\"Mask_Chin\":2,\"Mask_Nose_Mouth\":3}\n","    int_to_label = {0:\"Mask\",1:\"Mask_Mouth_Chin\",2:\"Mask_Chin\",3:\"Mask_Nose_Mouth\"}\n","\n","\n","    filename_prefix = '/content/sample_data/train_part'#/content/drive/MyDrive/GT/BigDataProject/train_part0.npy\n","    filename = filename_prefix + str(index) + \".npy\"\n","                \n","    X = np.load(filename, allow_pickle=True)\n","  \n","    x_mini_data =[]\n","    y_mini_data=[]\n","    mask = []    \n","    mask_prim = 0.0\n","    mask_sec = 1.0\n","\n","    for sample in X:\n","        \n","        norm_x_prim = normalise(sample[0])\n","\n","        label_int = sample[1]\n","        y_prim = [0] * NUM_CLASSES\n","\n","        if int_to_label[label_int]==\"Mask\":\n","          x_mini_data.append(norm_x_prim)\n","          y_prim[label_int] = 1 # y_ = [1,0,0]\n","          y_mini_data.append(y_prim)\n","          mask.append(mask_prim)\n","          \n","        else:\n","          x_mini_data.append(norm_x_prim)\n","          y_prim[1] = 1 # y_ = [0,1,0]\n","          y_mini_data.append(y_prim)\n","          mask.append(mask_prim)\n","\n","          # create a copy for x & y, add same x and new y for secondary task\n","          norm_x_sec = deepcopy(norm_x_prim)\n","          y_sec = [0] * NUM_CLASSES\n","          y_sec[label_int-1] = 1\n","          \n","          x_mini_data.append(norm_x_sec)\n","          y_mini_data.append(y_sec)\n","\n","          mask.append(mask_sec)\n","          \n","\n","    return x_mini_data, y_mini_data,mask\n","\n","\n","def create_random_mini_batches(X, Y, mask_mini, mini_batch_size = 32):\n","    \n","    m = len(X) # number of training examples\n","    mini_batches = []\n","    \n","    #Reshaping to convert Y to a 2D array from a rank one array\n","    X = np.array(X)\n","    Y = np.array(Y)\n","    Z = np.array(mask_mini)\n","    \n","    #Shuffle the data in each of the mini batch\n","    permutation = list(np.random.permutation(m))\n","    shuffled_X = X[permutation, :]\n","    shuffled_Y = Y[permutation, :]\n","    shuffled_Z = Z[permutation]\n","    \n","    n_mini_batches = math.ceil(m / mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n","    for k in range(n_mini_batches):\n","        \n","        start_pos = k * mini_batch_size\n","        end_pos = min(start_pos + mini_batch_size, m)\n","        \n","        mini_batch_X = shuffled_X[start_pos : end_pos, :]\n","        mini_batch_Y = shuffled_Y[start_pos : end_pos, :]\n","        mini_batch_Z = shuffled_Z[start_pos : end_pos]\n","        \n","        mini_batch = (mini_batch_X, mini_batch_Y,mini_batch_Z)\n","        mini_batches.append(mini_batch)\n","\n","    return mini_batches\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iGeqZ9ld3thm","executionInfo":{"status":"ok","timestamp":1638030140510,"user_tz":300,"elapsed":467,"user":{"displayName":"Sanjana Vijay Ganesh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07562438145748516192"}},"outputId":"03282407-47fb-4528-e513-b2a201d623f1"},"source":["import numpy as np\n","\n","def one_hot(indices, num_classes):\n","    tmp = np.zeros((indices.shape[0], num_classes), dtype=np.float32)\n","    tmp[np.arange(indices.shape[0]), indices] = 1.0\n","    return tmp\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n","  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n","  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n","  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n","  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n","  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U_Yc6Fi63thn","scrolled":true,"executionInfo":{"status":"ok","timestamp":1638857297489,"user_tz":300,"elapsed":3074,"user":{"displayName":"Sanjana Vijay Ganesh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07562438145748516192"}},"outputId":"c6a88574-5c8f-4fa6-c5ec-6c83c091bfb2"},"source":["sess = tf.compat.v1.InteractiveSession()\n","global_step = tf.contrib.framework.get_or_create_global_step()\n","\n","x, y_, mask = BKNetStyle.Input()\n","\n","y_prim_conv, y_sec_conv, phase_train, keep_prob = BKNetStyle.BKNetModel(x)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From <ipython-input-6-37db388bbb96>:2: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /content/BKNetStyle.py:37: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"30sQSN7v3tho","scrolled":true,"executionInfo":{"status":"error","timestamp":1638862043611,"user_tz":300,"elapsed":1613185,"user":{"displayName":"Sanjana Vijay Ganesh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07562438145748516192"}},"outputId":"a055dda1-c8b4-4d86-b361-d3f1d4c4ddbb"},"source":["prim_loss, sec_loss, l2_loss, loss = BKNetStyle.selective_loss(y_prim_conv, y_sec_conv, y_, mask)\n","\n","train_step = BKNetStyle.train_op(loss, global_step)\n","\n","prim_mask = tf.get_collection('prim_mask')[0]\n","sec_mask = tf.get_collection('sec_mask')[0]\n","\n","y_prim = tf.get_collection('y_prim')[0]\n","y_sec = tf.get_collection('y_sec')[0]\n","\n","prim_correct_prediction = tf.equal(tf.argmax(y_prim_conv, 1), tf.argmax(y_prim, 1))\n","sec_correct_prediction = tf.equal(tf.argmax(y_sec_conv, 1), tf.argmax(y_sec, 1))\n","\n","prim_true_pred = tf.reduce_sum(tf.cast(prim_correct_prediction, dtype=tf.float32) * prim_mask)\n","sec_true_pred = tf.reduce_sum(tf.cast(sec_correct_prediction, dtype=tf.float32) * sec_mask)\n","\n","saver = tf.train.Saver()\n","\n","if not os.path.isfile(SAVE_FOLDER + 'model.ckpt.index'):\n","    print('Create new model')\n","    sess.run(tf.global_variables_initializer())\n","    print('OK')\n","else:\n","    print('Restoring existed model')\n","    saver.restore(sess, SAVE_FOLDER + 'model.ckpt')\n","    print('OK')\n","\n","loss_summary_placeholder = tf.placeholder(tf.float32)\n","tf.summary.scalar('loss', loss_summary_placeholder)\n","merge_summary = tf.summary.merge_all()\n","writer = tf.summary.FileWriter(\"./summary/\")\n","\n","learning_rate = tf.get_collection('learning_rate')[0]\n","\n","current_epoch = (int)(global_step.eval() / (1000 // BATCH_SIZE)) \n","for epoch in range(current_epoch + 1, NUM_EPOCHS):\n","    tic_epoch = time.time()\n","    print('Epoch:', str(epoch))\n","\n","    avg_ttl = []\n","    avg_rgl = []\n","    avg_prim_loss = []\n","    avg_sec_loss = []\n","\n","    prim_nb_true_pred = 0\n","    sec_nb_true_pred = 0\n","\n","    prim_nb_train = 0\n","    sec_nb_train = 0\n","\n","    print(\"Learning rate: %f\" % learning_rate.eval())\n","       #lazy loading of dataset and training\n","    n_mini_batches = 0\n","    epoch_cost = 0\n","    total_time_taken_to_load_dataset = 0\n","    total_time_taken_to_create_mini_batches = 0            \n","    tic = time.time()\n","    #file_indices = get_shuffled_indices(1, 26) # todo change to total part files\n","    file_indices = np.arange(0, 61) #[0, 1, 2] #TODO - to remove\n","\n","    mini_batch_size = BATCH_SIZE\n","\n","    for j in file_indices:\n","        print(\"file \", j)\n","        X_mini = None\n","        Y_mini = None\n","\n","        lmd_tic = time.time()\n","        X_mini, Y_mini, mask_mini = load_mini_dataset(j)\n","        lmd_toc = time.time()\n","        total_time_taken_to_load_dataset += (lmd_toc-lmd_tic)\n","        #print(total_time_taken_to_load_dataset)\n","        \n","        rmb_tic = time.time()\n","        mini_batches = None\n","        mini_batches = create_random_mini_batches(X_mini, Y_mini, mask_mini, mini_batch_size = mini_batch_size) # todo Samarth add for mask\n","        rmb_toc = time.time()\n","        total_time_taken_to_create_mini_batches += (rmb_toc-rmb_tic)\n","        \n","        #bat_ind = 0\n","        for mini_batch in mini_batches:\n","            #print(\"at minibatch \", bat_ind)\n","            #bat_ind+=1\n","            batch_img = mini_batch[0] \n","            batch_label = mini_batch[1]\n","            batch_mask = mini_batch[2]\n","            \n","            curr_batch_size = batch_img.shape[0]\n","\n","            for i in range(curr_batch_size):\n","                if batch_mask[i] == 0.0:\n","                    prim_nb_train += 1\n","                else:\n","                    if batch_mask[i] == 1.0:\n","                        sec_nb_train += 1                        \n","\n","            batch_img = CNN2Head_input.augmentation(batch_img, 48)\n","\n","            ttl, pml, sel, l2l, _ = sess.run([loss, prim_loss, sec_loss, l2_loss, train_step],\n","                                                  feed_dict={x: batch_img, y_: batch_label, mask: batch_mask,\n","                                                            phase_train: True,\n","                                                            keep_prob: 0.5})\n","\n","            prim_nb_true_pred += sess.run(prim_true_pred, feed_dict={x: batch_img, y_: batch_label, mask: batch_mask,\n","                                                                      phase_train: True,\n","                                                                      keep_prob: 0.5})\n","\n","            sec_nb_true_pred += sess.run(sec_true_pred,\n","                                            feed_dict={x: batch_img, y_: batch_label, mask: batch_mask,\n","                                                      phase_train: True,\n","                                                      keep_prob: 0.5})\n","\n","\n","            avg_ttl.append(ttl)\n","            avg_prim_loss.append(pml)\n","            avg_sec_loss.append(sel)\n","            avg_rgl.append(l2l)\n","\n","    prim_train_accuracy = prim_nb_true_pred * 1.0 / prim_nb_train\n","    sec_train_accuracy = sec_nb_true_pred * 1.0 / sec_nb_train\n","\n","    avg_prim_loss = np.average(avg_prim_loss)\n","    avg_sec_loss = np.average(avg_sec_loss)\n","\n","    avg_rgl = np.average(avg_rgl)\n","    avg_ttl = np.average(avg_ttl)\n","    tic_epoch2 = time.time()\n","    print(tic_epoch2 - tic_epoch)\n","    \n","    with open('log.csv', 'w+') as f:\n","        f.write('{0},{1},{2},{3},{4},{5},{6}\\n'.format(current_epoch, prim_train_accuracy, sec_train_accuracy, avg_prim_loss, avg_sec_loss, avg_ttl, avg_rgl))\n","\n","    print('Primary task train accuracy: ' + str(prim_train_accuracy * 100))\n","    print('Secondary task train accuracy: ' + str(sec_train_accuracy * 100))\n","\n","    print('Total loss: ' + str(avg_ttl) + '. L2-loss: ' + str(avg_rgl))\n","    print('Primary loss: ' + str(avg_prim_loss))\n","    print('Secondary loss: ' + str(avg_sec_loss))\n","    \n","    print('\\n')\n","\n","    saver.save(sess, 'sample_data/' + 'model.ckpt')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Create new model\n","OK\n","Epoch: 1\n","Learning rate: 0.010000\n","file  0\n","file  1\n","file  2\n","file  3\n","file  4\n","file  5\n","file  6\n","file  7\n","file  8\n","file  9\n","file  10\n","file  11\n","file  12\n","file  13\n","file  14\n","file  15\n","file  16\n","file  17\n","file  18\n","file  19\n","file  20\n","file  21\n","file  22\n","file  23\n","file  24\n","file  25\n","file  26\n","file  27\n","file  28\n","file  29\n","file  30\n","file  31\n","file  32\n","file  33\n","file  34\n","file  35\n","file  36\n","file  37\n","file  38\n","file  39\n","file  40\n","file  41\n","file  42\n","file  43\n","file  44\n","file  45\n","file  46\n","file  47\n","file  48\n","file  49\n","file  50\n","file  51\n","file  52\n","file  53\n","file  54\n","file  55\n","file  56\n","file  57\n","file  58\n","file  59\n","file  60\n","235.29842734336853\n","Primary task train accuracy: 92.07868852459016\n","Secondary task train accuracy: 87.09729958630574\n","Total loss: 2.2310944. L2-loss: 1.6503676\n","Primary loss: 0.22532612\n","Secondary loss: 0.35540077\n","\n","\n","Epoch: 2\n","Learning rate: 0.010000\n","file  0\n","file  1\n","file  2\n","file  3\n","file  4\n","file  5\n","file  6\n","file  7\n","file  8\n","file  9\n","file  10\n","file  11\n","file  12\n","file  13\n","file  14\n","file  15\n","file  16\n","file  17\n","file  18\n","file  19\n","file  20\n","file  21\n","file  22\n","file  23\n","file  24\n","file  25\n","file  26\n","file  27\n","file  28\n","file  29\n","file  30\n","file  31\n","file  32\n","file  33\n","file  34\n","file  35\n","file  36\n","file  37\n","file  38\n","file  39\n","file  40\n","file  41\n","file  42\n","file  43\n","file  44\n","file  45\n","file  46\n","file  47\n","file  48\n","file  49\n","file  50\n","file  51\n","file  52\n","file  53\n","file  54\n","file  55\n","file  56\n","file  57\n","file  58\n","file  59\n","file  60\n","227.316468000412\n","Primary task train accuracy: 96.2344262295082\n","Secondary task train accuracy: 95.98358252711814\n","Total loss: 0.9670795. L2-loss: 0.6599827\n","Primary loss: 0.13626552\n","Secondary loss: 0.17083123\n","\n","\n","Epoch: 3\n","Learning rate: 0.010000\n","file  0\n","file  1\n","file  2\n","file  3\n","file  4\n","file  5\n","file  6\n","file  7\n","file  8\n","file  9\n","file  10\n","file  11\n","file  12\n","file  13\n","file  14\n","file  15\n","file  16\n","file  17\n","file  18\n","file  19\n","file  20\n","file  21\n","file  22\n","file  23\n","file  24\n","file  25\n","file  26\n","file  27\n","file  28\n","file  29\n","file  30\n","file  31\n","file  32\n","file  33\n","file  34\n","file  35\n","file  36\n","file  37\n","file  38\n","file  39\n","file  40\n","file  41\n","file  42\n","file  43\n","file  44\n","file  45\n","file  46\n","file  47\n","file  48\n","file  49\n","file  50\n","file  51\n","file  52\n","file  53\n","file  54\n","file  55\n","file  56\n","file  57\n","file  58\n","file  59\n","file  60\n","226.7508189678192\n","Primary task train accuracy: 95.93770491803278\n","Secondary task train accuracy: 95.85002768819831\n","Total loss: 0.81154263. L2-loss: 0.5052856\n","Primary loss: 0.13618128\n","Secondary loss: 0.1700757\n","\n","\n","Epoch: 4\n","Learning rate: 0.009500\n","file  0\n","file  1\n","file  2\n","file  3\n","file  4\n","file  5\n","file  6\n","file  7\n","file  8\n","file  9\n","file  10\n","file  11\n","file  12\n","file  13\n","file  14\n","file  15\n","file  16\n","file  17\n","file  18\n","file  19\n","file  20\n","file  21\n","file  22\n","file  23\n","file  24\n","file  25\n","file  26\n","file  27\n","file  28\n","file  29\n","file  30\n","file  31\n","file  32\n","file  33\n","file  34\n","file  35\n","file  36\n","file  37\n","file  38\n","file  39\n","file  40\n","file  41\n","file  42\n","file  43\n","file  44\n","file  45\n","file  46\n","file  47\n","file  48\n","file  49\n","file  50\n","file  51\n","file  52\n","file  53\n","file  54\n","file  55\n","file  56\n","file  57\n","file  58\n","file  59\n","file  60\n","227.11521410942078\n","Primary task train accuracy: 98.59344262295082\n","Secondary task train accuracy: 98.6839962213753\n","Total loss: 0.47939277. L2-loss: 0.32663256\n","Primary loss: 0.07146524\n","Secondary loss: 0.08129498\n","\n","\n","Epoch: 5\n","Learning rate: 0.009500\n","file  0\n","file  1\n","file  2\n","file  3\n","file  4\n","file  5\n","file  6\n","file  7\n","file  8\n","file  9\n","file  10\n","file  11\n","file  12\n","file  13\n","file  14\n","file  15\n","file  16\n","file  17\n","file  18\n","file  19\n","file  20\n","file  21\n","file  22\n","file  23\n","file  24\n","file  25\n","file  26\n","file  27\n","file  28\n","file  29\n","file  30\n","file  31\n","file  32\n","file  33\n","file  34\n","file  35\n","file  36\n","file  37\n","file  38\n","file  39\n","file  40\n","file  41\n","file  42\n","file  43\n","file  44\n","file  45\n","file  46\n","file  47\n","file  48\n","file  49\n","file  50\n","file  51\n","file  52\n","file  53\n","file  54\n","file  55\n","file  56\n","file  57\n","file  58\n","file  59\n","file  60\n","227.2077932357788\n","Primary task train accuracy: 99.2327868852459\n","Secondary task train accuracy: 99.19867096648099\n","Total loss: 0.32493892. L2-loss: 0.2142297\n","Primary loss: 0.04821346\n","Secondary loss: 0.06249578\n","\n","\n","Epoch: 6\n","Learning rate: 0.009500\n","file  0\n","file  1\n","file  2\n","file  3\n","file  4\n","file  5\n","file  6\n","file  7\n","file  8\n","file  9\n","file  10\n","file  11\n","file  12\n","file  13\n","file  14\n","file  15\n","file  16\n","file  17\n","file  18\n","file  19\n","file  20\n","file  21\n","file  22\n","file  23\n","file  24\n","file  25\n","file  26\n","file  27\n","file  28\n","file  29\n","file  30\n","file  31\n","file  32\n","file  33\n","file  34\n","file  35\n","file  36\n","file  37\n","file  38\n","file  39\n","file  40\n","file  41\n","file  42\n","file  43\n","file  44\n","file  45\n","file  46\n","file  47\n","file  48\n","file  49\n","file  50\n","file  51\n","file  52\n","file  53\n","file  54\n","file  55\n","file  56\n","file  57\n","file  58\n","file  59\n","file  60\n","226.85811972618103\n","Primary task train accuracy: 99.61803278688525\n","Secondary task train accuracy: 99.50486986546792\n","Total loss: 0.24195376. L2-loss: 0.16143958\n","Primary loss: 0.03266348\n","Secondary loss: 0.0478507\n","\n","\n","Epoch: 7\n","Learning rate: 0.009025\n","file  0\n","file  1\n","file  2\n","file  3\n","file  4\n","file  5\n","file  6\n","file  7\n","file  8\n","file  9\n","file  10\n","file  11\n","file  12\n","file  13\n","file  14\n","file  15\n","file  16\n","file  17\n","file  18\n","file  19\n","file  20\n","file  21\n","file  22\n","file  23\n","file  24\n","file  25\n","file  26\n","file  27\n","file  28\n","file  29\n","file  30\n","file  31\n","file  32\n","file  33\n","file  34\n","file  35\n","file  36\n","file  37\n","file  38\n","file  39\n","file  40\n","file  41\n","file  42\n","file  43\n","file  44\n","file  45\n","file  46\n","file  47\n","file  48\n","file  49\n","file  50\n","file  51\n","file  52\n","file  53\n","file  54\n","file  55\n","file  56\n","file  57\n","file  58\n","file  59\n","file  60\n","226.46568179130554\n","Primary task train accuracy: 99.69016393442624\n","Secondary task train accuracy: 99.69705853610866\n","Total loss: 0.21322723. L2-loss: 0.1416657\n","Primary loss: 0.030203074\n","Secondary loss: 0.04135846\n","\n","\n","Epoch: 8\n","Learning rate: 0.009025\n","file  0\n","file  1\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-f7021e2b16b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    148\u001b[0m                                                   feed_dict={x: batch_img, y_: batch_label, mask: batch_mask,\n\u001b[1;32m    149\u001b[0m                                                             \u001b[0mphase_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                                                             keep_prob: 0.5})\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             prim_nb_true_pred += sess.run(prim_true_pred, feed_dict={x: batch_img, y_: batch_label, mask: batch_mask,\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cJV2PBlLdsXF","executionInfo":{"status":"ok","timestamp":1638857319332,"user_tz":300,"elapsed":276,"user":{"displayName":"Sanjana Vijay Ganesh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07562438145748516192"}},"outputId":"a296f3e0-7b78-46eb-cbeb-77d60af542d3"},"source":["#debug\n"," \n","from tensorflow.python.client import device_lib\n","\n","def get_available_gpus():\n","    local_device_protos = device_lib.list_local_devices()\n","    print(local_device_protos)\n","    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n","\n","print(get_available_gpus())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 13808043833954068218\n",", name: \"/device:XLA_CPU:0\"\n","device_type: \"XLA_CPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 272769565268015323\n","physical_device_desc: \"device: XLA_CPU device\"\n",", name: \"/device:XLA_GPU:0\"\n","device_type: \"XLA_GPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 2850385044571302443\n","physical_device_desc: \"device: XLA_GPU device\"\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 11338832282\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 2516489293699904995\n","physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n","]\n","['/device:GPU:0']\n"]}]},{"cell_type":"code","metadata":{"id":"f_yqNPtv3thr"},"source":[""],"execution_count":null,"outputs":[]}]}
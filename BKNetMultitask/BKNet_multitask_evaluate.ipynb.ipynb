{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN2Head_evaluate.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"cells":[{"cell_type":"code","metadata":{"id":"lqTV4LMgvz46","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638404680238,"user_tz":300,"elapsed":44498,"user":{"displayName":"Sanjana Vijay Ganesh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07562438145748516192"}},"outputId":"cd0670ce-e381-46b4-bff5-470501480443"},"source":["!pip install tensorflow-gpu==1.13.1"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow-gpu==1.13.1\n","  Downloading tensorflow_gpu-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (345.0 MB)\n","\u001b[K     |████████████████████████████████| 345.0 MB 3.6 kB/s \n","\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.1.2)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.15.0)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (0.4.0)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.19.5)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.42.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (3.17.3)\n","Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (0.12.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (0.37.0)\n","Collecting tensorboard<1.14.0,>=1.13.0\n","  Downloading tensorboard-1.13.1-py3-none-any.whl (3.2 MB)\n","\u001b[K     |████████████████████████████████| 3.2 MB 41.8 MB/s \n","\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (0.8.1)\n","Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n","  Downloading tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367 kB)\n","\u001b[K     |████████████████████████████████| 367 kB 75.8 MB/s \n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.1.0)\n","Collecting keras-applications>=1.0.6\n","  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 6.6 MB/s \n","\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.13.1) (3.1.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.3.6)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (1.0.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (4.8.2)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.10.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.6.0)\n","Collecting mock>=2.0.0\n","  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow-gpu==1.13.1) (1.5.2)\n","Installing collected packages: mock, tensorflow-estimator, tensorboard, keras-applications, tensorflow-gpu\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.7.0\n","    Uninstalling tensorflow-estimator-2.7.0:\n","      Successfully uninstalled tensorflow-estimator-2.7.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.7.0\n","    Uninstalling tensorboard-2.7.0:\n","      Successfully uninstalled tensorboard-2.7.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.7.0 requires tensorboard~=2.6, but you have tensorboard 1.13.1 which is incompatible.\n","tensorflow 2.7.0 requires tensorflow-estimator<2.8,~=2.7.0rc0, but you have tensorflow-estimator 1.13.0 which is incompatible.\u001b[0m\n","Successfully installed keras-applications-1.0.8 mock-4.0.3 tensorboard-1.13.1 tensorflow-estimator-1.13.0 tensorflow-gpu-1.13.1\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GugvVhUjRIZr","executionInfo":{"status":"ok","timestamp":1639021036390,"user_tz":300,"elapsed":3254,"user":{"displayName":"Sanjana Vijay Ganesh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07562438145748516192"}},"outputId":"b60563ce-67e0-448b-c4e8-dd9b0afe0d1b"},"source":["!pip install tensorflow==1.13.1"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow==1.13.1 in /usr/local/lib/python3.7/dist-packages (1.13.1)\n","Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.13.1)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.4.0)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.0.8)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.42.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.2)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.15.0)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.19.5)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.8.1)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (3.17.3)\n","Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.13.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.0)\n","Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.12.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.37.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (3.1.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.3.6)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (1.0.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (4.8.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.6.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.10.0.2)\n","Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.1) (4.0.3)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.13.1) (1.5.2)\n"]}]},{"cell_type":"code","metadata":{"id":"UkTthIob3the","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639021028274,"user_tz":300,"elapsed":1386,"user":{"displayName":"Sanjana Vijay Ganesh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07562438145748516192"}},"outputId":"9aae616f-2853-4acc-9a93-50e22b3fa7c9"},"source":["import os\n","import numpy as np\n","import tensorflow as tf\n","\n","import BKNetStyle\n","from const import *\n","import time\n","import math\n","%load_ext autoreload\n","%autoreload 2\n","from copy import copy, deepcopy"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ao5lG9eQ34kQ","executionInfo":{"status":"ok","timestamp":1638030263608,"user_tz":300,"elapsed":24039,"user":{"displayName":"Sanjana Vijay Ganesh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07562438145748516192"}},"outputId":"0f6c9ec7-688c-45dd-a008-f2761a4fe29c"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"UaW23Cd33thk"},"source":["NUM_CLASSES = 3\n","\n","def normalise(x):\n","    return (x-128)/255.0\n","\n","def load_mini_dataset(index):\n","    \n","    label_to_int = {\"Mask\":0,\"Mask_Mouth_Chin\":1,\"Mask_Chin\":2,\"Mask_Nose_Mouth\":3}\n","    int_to_label = {0:\"Mask\",1:\"Mask_Mouth_Chin\",2:\"Mask_Chin\",3:\"Mask_Nose_Mouth\"}\n","\n","\n","    filename_prefix = '/content/sample_data/test_part'#/content/drive/MyDrive/GT/BigDataProject/train_part0.npy\n","    filename = filename_prefix + str(index) + \".npy\"\n","                \n","    X = np.load(filename, allow_pickle=True)\n","  \n","    x_mini_data =[]\n","    y_mini_data=[]\n","    mask = []    \n","    mask_prim = 0.0\n","    mask_sec = 1.0\n","\n","    for sample in X:\n","        \n","        norm_x_prim = normalise(sample[0]) # todo check output once\n","\n","        label_int = sample[1]\n","        y_prim = [0] * NUM_CLASSES\n","\n","        if int_to_label[label_int]==\"Mask\":\n","          x_mini_data.append(norm_x_prim)\n","          y_prim[label_int] = 1 # y_ = [1,0,0]\n","          y_mini_data.append(y_prim)\n","          mask.append(mask_prim)\n","          \n","        else:\n","          x_mini_data.append(norm_x_prim)\n","          y_prim[1] = 1 # y_ = [0,1,0]\n","          y_mini_data.append(y_prim)\n","          mask.append(mask_prim)\n","\n","          # create a copy for x & y, add same x and new y for secondary task\n","          norm_x_sec = deepcopy(norm_x_prim)\n","          y_sec = [0] * NUM_CLASSES\n","          y_sec[label_int-1] = 1\n","          \n","          x_mini_data.append(norm_x_sec)\n","          y_mini_data.append(y_sec)\n","\n","          mask.append(mask_sec)\n","          \n","\n","    return x_mini_data, y_mini_data,mask\n","\n","\n","def create_random_mini_batches(X, Y, mask_mini, mini_batch_size = 32):\n","    \n","    m = len(X) # number of training examples\n","    mini_batches = []\n","    \n","    #Reshaping to convert Y to a 2D array from a rank one array\n","    X = np.array(X)\n","    Y = np.array(Y)\n","    Z = np.array(mask_mini)\n","    \n","    #Shuffle the data in each of the mini batch\n","    permutation = list(np.random.permutation(m))\n","    shuffled_X = X#[permutation, :]\n","    shuffled_Y = Y#[permutation, :]\n","    shuffled_Z = Z#[permutation]\n","    \n","    n_mini_batches = math.ceil(m / mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n","    for k in range(n_mini_batches):\n","        \n","        start_pos = k * mini_batch_size\n","        end_pos = min(start_pos + mini_batch_size, m)\n","        \n","        mini_batch_X = shuffled_X[start_pos : end_pos, :]\n","        mini_batch_Y = shuffled_Y[start_pos : end_pos, :]\n","        mini_batch_Z = shuffled_Z[start_pos : end_pos]\n","        \n","        mini_batch = (mini_batch_X, mini_batch_Y,mini_batch_Z)\n","        mini_batches.append(mini_batch)\n","\n","    return mini_batches\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iGeqZ9ld3thm","executionInfo":{"status":"ok","timestamp":1638030140510,"user_tz":300,"elapsed":467,"user":{"displayName":"Sanjana Vijay Ganesh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07562438145748516192"}},"outputId":"03282407-47fb-4528-e513-b2a201d623f1"},"source":["import numpy as np\n","\n","def one_hot(indices, num_classes):\n","    tmp = np.zeros((indices.shape[0], num_classes), dtype=np.float32)\n","    tmp[np.arange(indices.shape[0]), indices] = 1.0\n","    return tmp\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n","  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n","  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n","  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n","  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n","  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U_Yc6Fi63thn","scrolled":true,"executionInfo":{"status":"ok","timestamp":1639021047915,"user_tz":300,"elapsed":2337,"user":{"displayName":"Sanjana Vijay Ganesh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07562438145748516192"}},"outputId":"108fe49e-c178-4248-945b-4eda4c8bd5ed"},"source":["sess = tf.compat.v1.InteractiveSession()\n","global_step = tf.contrib.framework.get_or_create_global_step()\n","\n","x, y_, mask = BKNetStyle.Input()\n","\n","y_prim_conv, y_sec_conv, phase_train, keep_prob = BKNetStyle.BKNetModel(x)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From <ipython-input-4-37db388bbb96>:2: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /content/BKNetStyle.py:37: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"30sQSN7v3tho","scrolled":true,"executionInfo":{"status":"ok","timestamp":1638864533644,"user_tz":300,"elapsed":1550830,"user":{"displayName":"Sanjana Vijay Ganesh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07562438145748516192"}},"outputId":"a9d8087b-d107-4b2f-d5b5-71b92032fe13"},"source":["prim_loss, sec_loss, l2_loss, loss = BKNetStyle.selective_loss(y_prim_conv, y_sec_conv, y_, mask)\n","\n","train_step = BKNetStyle.train_op(loss, global_step)\n","\n","prim_mask = tf.get_collection('prim_mask')[0]\n","sec_mask = tf.get_collection('sec_mask')[0]\n","\n","y_prim = tf.get_collection('y_prim')[0]\n","y_sec = tf.get_collection('y_sec')[0]\n","\n","prim_correct_prediction = tf.equal(tf.argmax(y_prim_conv, 1), tf.argmax(y_prim, 1))\n","sec_correct_prediction = tf.equal(tf.argmax(y_sec_conv, 1), tf.argmax(y_sec, 1))\n","\n","prim_true_pred = tf.reduce_sum(tf.cast(prim_correct_prediction, dtype=tf.float32) * prim_mask)\n","sec_true_pred = tf.reduce_sum(tf.cast(sec_correct_prediction, dtype=tf.float32) * sec_mask)\n","\n","saver = tf.train.Saver()\n","print('Restoring existed model')\n","saver.restore(sess, \"/content/models/\" + 'model.ckpt')\n","print('OK')\n","\n","loss_summary_placeholder = tf.placeholder(tf.float32)\n","tf.summary.scalar('loss', loss_summary_placeholder)\n","merge_summary = tf.summary.merge_all()\n","writer = tf.summary.FileWriter(\"./summary/\")\n","\n","avg_prim_loss = []\n","avg_sec_loss = []\n","\n","prim_nb_true_pred = 0\n","sec_nb_true_pred = 0\n","\n","prim_nb_train = 0\n","sec_nb_train = 0\n","\n","    #added by Samarth; lazy loading of dataset and training\n","n_mini_batches = 0\n","epoch_cost = 0\n","total_time_taken_to_load_dataset = 0\n","total_time_taken_to_create_mini_batches = 0            \n","tic = time.time()\n","#file_indices = get_shuffled_indices(1, 26) # todo change to total part files\n","file_indices = np.arange(0, 27) #[0, 1, 2] #TODO - to remove\n","\n","mini_batch_size = BATCH_SIZE\n","\n","true_pos_count = 0\n","false_pos_count = 0\n","false_neg_count = 0\n","true_neg_count = 0\n","TP = tf.count_nonzero(tf.cast(tf.argmax(y_prim_conv, 1) * tf.argmax(y_prim, 1), dtype=tf.float32) * prim_mask, axis=0)\n","FP = tf.count_nonzero(tf.cast(tf.argmax(y_prim_conv, 1) * (tf.argmax(y_prim, 1) - 1), dtype=tf.float32) * prim_mask, axis=0)\n","FN = tf.count_nonzero(tf.cast((tf.argmax(y_prim_conv, 1) - 1) * tf.argmax(y_prim, 1), dtype=tf.float32) * prim_mask, axis=0)\n","TN = tf.count_nonzero(tf.cast((tf.argmax(y_prim_conv, 1) - 1) * (tf.argmax(y_prim, 1) - 1), dtype=tf.float32) * prim_mask, axis=0)\n","\n","for j in file_indices:\n","    \n","    X_mini = None\n","    Y_mini = None\n","\n","    lmd_tic = time.time()\n","    print(\"at file index \", j)\n","    X_mini, Y_mini, mask_mini = load_mini_dataset(j) # todo Samarth add for mask - done\n","    #print(\"at file index \", j)\n","    lmd_toc = time.time()\n","    total_time_taken_to_load_dataset += (lmd_toc-lmd_tic)\n","    #print(total_time_taken_to_load_dataset)\n","    \n","    rmb_tic = time.time()\n","    mini_batches = None\n","    mini_batches = create_random_mini_batches(X_mini, Y_mini, mask_mini, mini_batch_size = mini_batch_size) # todo Samarth add for mask\n","    rmb_toc = time.time()\n","    total_time_taken_to_create_mini_batches += (rmb_toc-rmb_tic)\n","    \n","    \n","    '''for batch in range(number_batch):\n","    #       print('Training on batch {0}/{1}'.format(str(batch + 1), str(number_batch)))\n","    top = batch * BATCH_SIZE\n","    bot = min((batch + 1) * BATCH_SIZE, len(train_data))\n","    batch_img = np.asarray(train_img[top:bot])\n","    batch_label = np.asarray(train_label[top:bot])\n","    batch_mask = np.asarray(train_mask[top:bot])'''\n","    #bat_ind = 0\n","    for mini_batch in mini_batches:\n","        #print(\"at minibatch \", bat_ind)\n","        #bat_ind+=1\n","        batch_img = mini_batch[0] \n","        batch_label = mini_batch[1]\n","        batch_mask = mini_batch[2]\n","        \n","        # (batch_img, batch_label) = mini_batch\n","        curr_batch_size = batch_img.shape[0]\n","        # batch_mask = np.zeros(curr_batch_size) #todo comment Samarth - done\n","\n","        for i in range(curr_batch_size):\n","            if batch_mask[i] == 0.0:\n","                prim_nb_train += 1\n","            else:\n","                if batch_mask[i] == 1.0:\n","                    sec_nb_train += 1                        \n","                # else:\n","                #     age_nb_train += 1\n","\n","        #batch_img = CNN2Head_input.augmentation(batch_img, 48)\n","\n","        '''ttl, pml, sel, l2l, _ = sess.run([loss, prim_loss, sec_loss, l2_loss, train_step],\n","                                              feed_dict={x: batch_img, y_: batch_label, mask: batch_mask,\n","                                                        phase_train: True,\n","                                                        keep_prob: 0.5})'''\n","        #t = lmd_tic = time.time()\n","        prim_nb_true_pred += sess.run(prim_true_pred, feed_dict={x: batch_img, y_: batch_label, mask: batch_mask,\n","                                                                  phase_train: False,\n","                                                                  keep_prob: 0.5})\n","        #print('time taken', time.time() - t)\n","        sec_nb_true_pred += sess.run(sec_true_pred,\n","                                        feed_dict={x: batch_img, y_: batch_label, mask: batch_mask,\n","                                                  phase_train: False,\n","                                                  keep_prob: 0.5})\n","        \n","        true_pos, false_pos, false_neg, true_neg = sess.run([TP, FP, FN, TN], feed_dict={x: batch_img, y_: batch_label, mask: batch_mask,\n","                                                  phase_train: False,\n","                                                  keep_prob: 0.5})\n","        true_pos_count += true_pos\n","        false_pos_count += false_pos\n","        false_neg_count += false_neg\n","        true_neg_count += true_neg\n","        #print(prim_nb_true_pred, sec_nb_true_pred, prim_nb_train, sec_nb_train)\n","\n","        # age_nb_true_pred += sess.run(age_true_pred,\n","        #                                 feed_dict={x: batch_img, y_: batch_label, mask: batch_mask,\n","        #                                             phase_train: True,\n","        #                                             keep_prob: 0.5})\n","\n","        '''--------------------------------------- DEBUG -----------------------------------------------------'''\n","        '''\n","        sm_mask, em_mask, ge_mask = sess.run([smile_mask, gender_mask, age_mask],\n","                                            feed_dict={x: batch_img, y_: batch_label, mask: batch_mask,\n","                                                        phase_train: True,\n","                                                        keep_prob: 0.5})\n","        print('Smile mask: ', sm_mask)\n","        print('Gender mask', ge_mask)\n","        print('Age mask', ag_mask)\n","        print('Batch mask', batch_mask)\n","\n","        y_true_sm, y_true_ge, y_true_ag = sess.run([y_smile, y_gender, y_age],\n","                                                  feed_dict={x: batch_img, y_: batch_label, mask: batch_mask,\n","                                                              phase_train: True,\n","                                                              keep_prob: 0.5})\n","        print('Smile label', y_true_sm)\n","        print('Gender label', y_true_ge)\n","        print('Age label', y_true_ag)\n","        print('Batch label', batch_label)\n","\n","        y_conv_sm, y_conv_ge, y_conv_ag = sess.run([y_smile_conv, y_gender_conv, y_age_conv],\n","                                                  feed_dict={x: batch_img, y_: batch_label, mask: batch_mask,\n","                                                              phase_train: True,\n","                                                              keep_prob: 0.5})\n","        print('Smile conv', y_conv_sm)\n","        print('Gender conv', y_conv_ge)\n","        print('Age conv', y_conv_ag)\n","\n","        '''\n","        '''---------------------------------- END OF DEBUG ----------------------------------------------------'''\n","\n","            \n","\n","\n","prim_train_accuracy = prim_nb_true_pred * 1.0 / prim_nb_train\n","sec_train_accuracy = sec_nb_true_pred * 1.0 / sec_nb_train\n","precision_class0 = true_pos_count / (true_pos_count + false_pos_count)\n","recall_class0 = true_pos_count / (true_pos_count + false_neg_count)\n","f1_class0 = 2 * precision_class0 * recall_class0 / (precision_class0 + recall_class0)\n","print(true_pos_count, false_pos_count, false_neg_count, true_neg_count)\n","\n","precision_class1 = true_neg_count / (true_neg_count + false_neg_count)\n","recall_class1 = true_neg_count / (true_neg_count + false_pos_count)\n","f1_class1 = 2 * precision_class1 * recall_class1 / (precision_class1 + recall_class1)\n","    # age_train_accuracy = age_nb_true_pred * 1.0 / age_nb_train\n","\n","\n","#     print('Avg_ttl: ' + str(avg_ttl))\n","#     print('loss_summary_placeholder: ' + str(loss_summary_placeholder))\n","#     print('merge_summary: ' + str(merge_summary))\n","\n","    #summary = sess.run(merge_summary, feed_dict={loss_summary_placeholder: avg_ttl})\n","    #writer.add_summary(summary, global_step=epoch)\n","    \n","    #with open('log.csv', 'w+') as f:\n","        # epochs, smile_train_accuracy, gender_train_accuracy, age_train_accuracy,\n","        # avg_smile_loss, avg_gender_loss, avg_age_loss, avg_ttl, avg_rgl\n","        # f.write('{0},{1},{2},{3},{4},{5},{6},{7},{8}\\n'.format(current_epoch, smile_train_accuracy, gender_train_accuracy, age_train_accuracy, avg_smile_loss, avg_gender_loss, avg_age_loss, avg_ttl, avg_rgl))\n","        #f.write('{0},{1},{2},{3},{4},{5},{6}\\n'.format(current_epoch, prim_train_accuracy, sec_train_accuracy, avg_prim_loss, avg_sec_loss, avg_ttl, avg_rgl))\n","\n","print('Primary task train accuracy: ' + str(prim_train_accuracy * 100))\n","print('Secondary task train accuracy: ' + str(sec_train_accuracy * 100))\n","print('Precision: ', precision_class0)\n","print('Recall: ', recall_class0)\n","print('F1 score: ', f1_class0)\n","print('Precision: ', precision_class1)\n","print('Recall: ', recall_class1)\n","print('F1 score: ', f1_class1)\n","    # print('Age task train accuracy: ' + str(age_train_accuracy * 100))\n","\n","    #print('Total loss: ' + str(avg_ttl) + '. L2-loss: ' + str(avg_rgl))\n","    #print('Primary loss: ' + str(avg_prim_loss))\n","    #print('Secondary loss: ' + str(avg_sec_loss))\n","    # print('Age loss: ' + str(avg_age_loss))\n","    \n","print('\\n')\n","\n","    #saver.save(sess, 'sample_data/' + 'model.ckpt')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Restoring existed model\n","INFO:tensorflow:Restoring parameters from /content/models/model.ckpt\n","OK\n","at file index  0\n","at file index  1\n","at file index  2\n","at file index  3\n","at file index  4\n","at file index  5\n","at file index  6\n","at file index  7\n","at file index  8\n","at file index  9\n","at file index  10\n","at file index  11\n","at file index  12\n","at file index  13\n","at file index  14\n","at file index  15\n","at file index  16\n","at file index  17\n","at file index  18\n","at file index  19\n","at file index  20\n","at file index  21\n","at file index  22\n","at file index  23\n","at file index  24\n","at file index  25\n","at file index  26\n","13275 127 68 13287\n","Primary task train accuracy: 99.29738012482716\n","Secondary task train accuracy: 98.77089110394964\n","Precision:  0.9905238024175497\n","Recall:  0.9949036948212546\n","F1 score:  0.9927089175546832\n","Precision:  0.9949082740546612\n","Recall:  0.990532279707768\n","F1 score:  0.9927154544435728\n","\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cJV2PBlLdsXF","executionInfo":{"status":"ok","timestamp":1638422576477,"user_tz":300,"elapsed":158,"user":{"displayName":"Sanjana Vijay Ganesh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07562438145748516192"}},"outputId":"4c2b4bd2-d30e-4a90-8dba-28beec52dbfc"},"source":["\n","# import tensorflow as tf\n","# vector_zero = tf.constant(0., tf.float32, [100])\n","# print(vector_zero) \n","# a   c       \n","#tf.config.list_physical_devices('GPU')  \n","    \n","from tensorflow.python.client import device_lib\n"," \n","def get_available_gpus():\n","    local_device_protos = device_lib.list_local_devices()\n","    print(local_device_protos)\n","    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n","  \n","print(get_available_gpus())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 4306342662559310609\n",", name: \"/device:XLA_CPU:0\"\n","device_type: \"XLA_CPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 5937106106890450757\n","physical_device_desc: \"device: XLA_CPU device\"\n","]\n","[]\n"]}]},{"cell_type":"code","metadata":{"id":"f_yqNPtv3thr"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yKk5CQWP8v2_","executionInfo":{"status":"ok","timestamp":1639205736113,"user_tz":300,"elapsed":5,"user":{"displayName":"Sanjana Vijay Ganesh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07562438145748516192"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N47NVp8O95Eb","executionInfo":{"status":"ok","timestamp":1639205741194,"user_tz":300,"elapsed":146,"user":{"displayName":"Sanjana Vijay Ganesh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07562438145748516192"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Saving a copy of misclassified images"],"metadata":{"id":"RcxcFaRASVRL"}},{"cell_type":"code","source":["from PIL import Image\n","import cv2"],"metadata":{"id":"XTwUDMGEOkyl"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_C5vU81LdnFI","executionInfo":{"status":"ok","timestamp":1639025632221,"user_tz":300,"elapsed":1574840,"user":{"displayName":"Sanjana Vijay Ganesh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07562438145748516192"}},"outputId":"019bc850-4798-4a4c-a34c-ccd2b0f16e45"},"source":["\n","prim_loss, sec_loss, l2_loss, loss = BKNetStyle.selective_loss(y_prim_conv, y_sec_conv, y_, mask)\n","\n","train_step = BKNetStyle.train_op(loss, global_step)\n","\n","prim_mask = tf.get_collection('prim_mask')[0]\n","sec_mask = tf.get_collection('sec_mask')[0]\n","\n","y_prim = tf.get_collection('y_prim')[0]\n","y_sec = tf.get_collection('y_sec')[0]\n"," \n","prim_correct_prediction = tf.equal(tf.argmax(y_prim_conv, 1), tf.argmax(y_prim, 1))\n","sec_correct_prediction = tf.equal(tf.argmax(y_sec_conv, 1), tf.argmax(y_sec, 1))\n","\n","prim_true_pred = tf.reduce_sum(tf.cast(prim_correct_prediction, dtype=tf.float32) * prim_mask)\n","sec_true_pred = tf.reduce_sum(tf.cast(sec_correct_prediction, dtype=tf.float32) * sec_mask)\n","\n","saver = tf.train.Saver()\n","print('Restoring existed model')\n","saver.restore(sess, \"/content/models/\" + 'model.ckpt')\n","print('OK')\n","\n","loss_summary_placeholder = tf.placeholder(tf.float32)\n","tf.summary.scalar('loss', loss_summary_placeholder)\n","merge_summary = tf.summary.merge_all()\n","writer = tf.summary.FileWriter(\"./summary/\")\n","\n","avg_prim_loss = []\n","avg_sec_loss = []\n","\n","prim_nb_true_pred = 0\n","sec_nb_true_pred = 0\n","\n","prim_nb_train = 0\n","sec_nb_train = 0\n","\n","n_mini_batches = 0\n","epoch_cost = 0\n","total_time_taken_to_load_dataset = 0\n","total_time_taken_to_create_mini_batches = 0            \n","tic = time.time()\n","\n","file_indices = np.arange(20) #[0, 1, 2] #TODO - to remove\n","\n","mini_batch_size = 1\n","\n","true_pos_count = 0\n","false_pos_count = 0\n","false_neg_count = 0\n","true_neg_count = 0\n","TP = tf.cast(tf.argmax(y_prim_conv, 1) * tf.argmax(y_prim, 1), dtype=tf.float32) * prim_mask\n","FP = tf.cast(tf.argmax(y_prim_conv, 1) * (tf.argmax(y_prim, 1) - 1), dtype=tf.float32) * prim_mask\n","FN = tf.cast((tf.argmax(y_prim_conv, 1) - 1) * tf.argmax(y_prim, 1), dtype=tf.float32) * prim_mask\n","TN = tf.cast((tf.argmax(y_prim_conv, 1) - 1) * (tf.argmax(y_prim, 1) - 1), dtype=tf.float32) * prim_mask\n","\n","op = tf.argmax(y_prim_conv, 1)\n","gt_op = tf.argmax(y_prim, 1)\n","\n","p_mask = prim_mask\n","\n","for j in file_indices:\n","    \n","    X_mini = None\n","    Y_mini = None\n","\n","    lmd_tic = time.time()\n","    X_mini, Y_mini, mask_mini = load_mini_dataset(j) # todo Samarth add for mask - done\n","    print(\"at file index \", j)\n","    lmd_toc = time.time()\n","    total_time_taken_to_load_dataset += (lmd_toc-lmd_tic)\n","    \n","    rmb_tic = time.time()\n","    mini_batches = None\n","    mini_batches = create_random_mini_batches(X_mini, Y_mini, mask_mini, mini_batch_size = mini_batch_size) # todo Samarth add for mask\n","    rmb_toc = time.time()\n","    total_time_taken_to_create_mini_batches += (rmb_toc-rmb_tic)\n","    \n","    bat_ind = 0\n","    for mini_batch in mini_batches:\n","        #print(\"at minibatch \", bat_ind)\n","        bat_ind+=1\n","        batch_img = mini_batch[0] \n","        batch_label = mini_batch[1]\n","        batch_mask = mini_batch[2]\n","        curr_batch_size = batch_img.shape[0]\n","\n","        for i in range(curr_batch_size):\n","            if batch_mask[i] == 0.0:\n","                prim_nb_train += 1\n","            else:\n","                if batch_mask[i] == 1.0:\n","                    sec_nb_train += 1                           \n","\n","        prim_nb_true_pred += sess.run(prim_true_pred, feed_dict={x: batch_img, y_: batch_label, mask: batch_mask,\n","                                                                  phase_train: False,\n","                                                                  keep_prob: 0.5})\n","\n","        sec_nb_true_pred += sess.run(sec_true_pred,\n","                                        feed_dict={x: batch_img, y_: batch_label, mask: batch_mask,\n","                                                  phase_train: False,\n","                                                  keep_prob: 0.5})\n","        \n","        #op1, gt_op1, p_mask1, TP1, FP1, TN1, FN1 = sess.run([op, gt_op, p_mask, TP, FP, TN, FN], feed_dict={x: batch_img, y_: batch_label, mask: batch_mask,\n","        #                                          phase_train: False,\n","        #                                          keep_prob: 0.5})\n","        \n","        y_prim_op, y_sec_op = sess.run([y_prim_conv, y_sec_conv], feed_dict={x: batch_img, y_: batch_label, mask: batch_mask, phase_train: False, keep_prob: 0.5})\n","\n","        pred = np.argmax(y_prim_op, axis=1)\n","        true = np.argmax(batch_label, axis=1)\n","        \n","        if(int(true) != int(pred) and int(batch_mask) == 0):\n","            #0-properly worn    1-improperly worn\n","            print(bat_ind, pred, true)\n","            denorm = (batch_img[0] * 255.0) + 128 \n","            rgb = cv2.cvtColor(np.uint8(denorm),cv2.COLOR_GRAY2RGB)\n","            resized_rgb = cv2.resize(rgb, (128,128)) \n","            cv2.imwrite('./sample_images/check' +str(j) + \"_\" + str(bat_ind) + '.png',resized_rgb)\n","\n","\n","prim_train_accuracy = prim_nb_true_pred * 1.0 / prim_nb_train\n","sec_train_accuracy = sec_nb_true_pred * 1.0 / sec_nb_train\n","\n","print('Primary task train accuracy: ' + str(prim_train_accuracy * 100))\n","print('Secondary task train accuracy: ' + str(sec_train_accuracy * 100))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Restoring existed model\n","INFO:tensorflow:Restoring parameters from /content/models/model.ckpt\n","OK\n","at file index  0\n","168 [1] [0]\n","206 [0] [1]\n","305 [0] [1]\n","382 [0] [1]\n","391 [0] [1]\n","409 [0] [1]\n","1012 [0] [1]\n","at file index  1\n","506 [0] [1]\n","747 [1] [0]\n","953 [0] [1]\n","1049 [1] [0]\n","1323 [0] [1]\n","1400 [0] [1]\n","at file index  2\n","87 [0] [1]\n","762 [0] [1]\n","935 [0] [1]\n","1103 [0] [1]\n","1311 [0] [1]\n","at file index  3\n","165 [0] [1]\n","408 [0] [1]\n","419 [0] [1]\n","464 [0] [1]\n","470 [0] [1]\n","599 [0] [1]\n","835 [1] [0]\n","836 [0] [1]\n","1083 [1] [0]\n","1198 [0] [1]\n","1306 [1] [0]\n","1362 [1] [0]\n","at file index  4\n","41 [0] [1]\n","150 [1] [0]\n","597 [0] [1]\n","638 [0] [1]\n","788 [0] [1]\n","1208 [0] [1]\n","1490 [0] [1]\n","at file index  5\n","545 [0] [1]\n","564 [0] [1]\n","688 [0] [1]\n","1137 [0] [1]\n","1230 [0] [1]\n","1308 [0] [1]\n","at file index  6\n","326 [0] [1]\n","555 [0] [1]\n","591 [0] [1]\n","618 [0] [1]\n","756 [0] [1]\n","1035 [0] [1]\n","1224 [0] [1]\n","1492 [0] [1]\n","at file index  7\n","616 [0] [1]\n","691 [0] [1]\n","880 [0] [1]\n","1118 [0] [1]\n","at file index  8\n","313 [0] [1]\n","700 [0] [1]\n","888 [0] [1]\n","1199 [0] [1]\n","1401 [0] [1]\n","at file index  9\n","534 [0] [1]\n","704 [0] [1]\n","1353 [0] [1]\n","at file index  10\n","183 [0] [1]\n","269 [0] [1]\n","324 [0] [1]\n","432 [0] [1]\n","468 [0] [1]\n","775 [0] [1]\n","1003 [1] [0]\n","at file index  11\n","186 [0] [1]\n","1037 [0] [1]\n","1157 [1] [0]\n","at file index  12\n","70 [0] [1]\n","1332 [0] [1]\n","at file index  13\n","1 [0] [1]\n","113 [0] [1]\n","145 [0] [1]\n","257 [1] [0]\n","316 [0] [1]\n","318 [0] [1]\n","704 [0] [1]\n","830 [0] [1]\n","988 [0] [1]\n","1307 [1] [0]\n","1370 [1] [0]\n","at file index  14\n","71 [0] [1]\n","669 [0] [1]\n","918 [0] [1]\n","1241 [0] [1]\n","at file index  15\n","119 [0] [1]\n","237 [0] [1]\n","514 [0] [1]\n","555 [0] [1]\n","640 [0] [1]\n","659 [0] [1]\n","967 [0] [1]\n","at file index  16\n","406 [0] [1]\n","527 [0] [1]\n","662 [0] [1]\n","675 [0] [1]\n","1350 [0] [1]\n","at file index  17\n","70 [0] [1]\n","258 [0] [1]\n","511 [0] [1]\n","771 [0] [1]\n","870 [0] [1]\n","1002 [0] [1]\n","1087 [0] [1]\n","1369 [0] [1]\n","at file index  18\n","86 [0] [1]\n","310 [0] [1]\n","382 [0] [1]\n","522 [0] [1]\n","733 [0] [1]\n","1099 [0] [1]\n","1286 [0] [1]\n","at file index  19\n","145 [0] [1]\n","313 [0] [1]\n","493 [0] [1]\n","718 [1] [0]\n","921 [0] [1]\n","1056 [0] [1]\n","1089 [1] [0]\n","1142 [0] [1]\n","1412 [0] [1]\n","Primary task train accuracy: 99.395\n","Secondary task train accuracy: 99.02659307576518\n"]}]},{"cell_type":"code","metadata":{"id":"sEVQ2gMClZCu"},"source":["op_2 = tf.argmax(y_sec_conv, 1)\n","gt_op_2 = tf.argmax(y_sec, 1)  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cp9DcLlakU5v"},"source":["#to delete\n","label_to_int = {\"Mask\":0,\"Mask_Mouth_Chin\":1,\"Mask_Chin\":2,\"Mask_Nose_Mouth\":3}\n","int_to_label = {0:\"Mask\",1:\"Mask_Mouth_Chin\",2:\"Mask_Chin\",3:\"Mask_Nose_Mouth\"}\n","def predict_single_image(file_index, img_index):\n","    filename_prefix = '/content/sample_data/test_part'#/content/drive/MyDrive/GT/BigDataProject/train_part0.npy\n","    filename = filename_prefix + str(file_index) + \".npy\"\n","    X = np.load(filename, allow_pickle=True)\n","  \n","    mask_prim = 0.0\n","    mask_sec = 1.0\n","\n","    sample = X[img_index]\n","        \n","    norm_x_prim = normalise(sample[0]) # todo check output once\n","    x_mini_data =[]\n","    y_mini_data=[]\n","    mask = []    \n","    mask_prim = 0.0\n","    mask_sec = 1.0\n","    label_int = sample[1]\n","    y_exp_prim = [0] * NUM_CLASSES\n","    if int_to_label[label_int]==\"Mask\":\n","        x_mini_data.append(norm_x_prim)\n","        y_exp_prim[label_int] = 1 # y_ = [1,0,0]\n","        y_mini_data.append(y_exp_prim)\n","        mask.append(mask_prim)\n","          \n","    else:\n","        x_mini_data.append(norm_x_prim)\n","        y_exp_prim[1] = 1 # y_ = [0,1,0]\n","        y_mini_data.append(y_exp_prim)\n","        mask.append(mask_prim)\n","    print(x_mini_data)\n","    x_data = np.array(x_mini_data)\n","    y_data = np.array(y_mini_data)\n","    mask_data = np.array(mask)\n","    print(x_data.type)\n","    print(y_data)\n","    print(mask_data)\n","    y_prim_op, y_sec_op = sess.run([y_prim_conv, y_sec_conv], feed_dict={x: x_data, y_: y_data, mask: mask_data, phase_train: False, keep_prob: 0.5})\n","    \n","    print(y_prim_op)\n","    print(y_sec_op)\n","    print(sample[0].shape)\n","    rgb = cv2.cvtColor(np.uint8(sample[0]),cv2.COLOR_GRAY2RGB)\n","    print(rgb.shape)\n","    resized_rgb = cv2.resize(rgb, (128,128)) #, interpolation = cv2.INTER_AREA\n","    #print(resized_grey.shape)\n","    cv2.imwrite('./check1.png',resized_rgb)\n","    \n","    #print(resized_rgb.shape)\n","    #cv2.imshow(resized_rgb)\n","    \n","    #pil_image=Image.fromarray(sample[0].squeeze(), 'L')\n","    #pil_image = pil_image.resize((256, 256), Image.ANTIALIAS)\n","    #pil_image.save('./chk1.png')\n","    #print(op_val_1, op_val_2)\n","    print(label_int)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LTezVQ08lqvE"},"source":["predict_single_image(0, 234)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"vZ3li6Fio239","executionInfo":{"status":"ok","timestamp":1638412913536,"user_tz":300,"elapsed":153,"user":{"displayName":"Sanjana Vijay Ganesh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07562438145748516192"}},"outputId":"7b1a24b0-969c-45f0-89d3-51eb25386f99"},"source":["%pwd"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content'"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","metadata":{"id":"roKWih62BQla"},"source":[""],"execution_count":null,"outputs":[]}]}